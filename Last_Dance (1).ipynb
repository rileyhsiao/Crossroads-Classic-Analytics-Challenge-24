{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FIfNoeAMYzc",
        "outputId": "76a301e7-2d23-43da-b56d-a3000f1297ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbpdhUXT_DTV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def dateconvert(df,column,reference_date):\n",
        "    # Convert 'date_column' to datetime\n",
        "    df[column] = pd.to_datetime(df[column])\n",
        "\n",
        "    df[f'{column}_year'] = df[column].dt.year\n",
        "    df[f'{column}_month'] = df[column].dt.month\n",
        "    df[f'{column}_weekday'] = df[column].dt.weekday\n",
        "    df[f'{column}_year'] = df[f'{column}_year'].fillna('NO')\n",
        "    df[f'{column}_month'] = df[f'{column}_month'].fillna('NO')\n",
        "    df[f'{column}_weekday'] = df[f'{column}_weekday'].fillna('NO')\n",
        "\n",
        "    # Specify a reference date\n",
        "     #'2022-01-01'\n",
        "\n",
        "    # Convert date to numeric value representing days since reference date\n",
        "    df[column] = (pd.to_datetime(reference_date)-df[column]).dt.days\n",
        "    if column == \"EventBeginDate\":\n",
        "        df[column] = df[column].fillna(654)\n",
        "    elif column == \"EventEndDate\":\n",
        "        df[column] = df[column].fillna(654)\n",
        "    elif column == \"CustomerFirstWBBActionDate\":\n",
        "        df[column] = df[column].fillna(5023)\n",
        "    elif column == \"CustomerFirstWBBPurchaseDate\":\n",
        "        df[column] = df[column].fillna(4842)\n",
        "    elif column == \"CustomerLastWBBActionDate\":\n",
        "        df[column] = df[column].fillna(4807)\n",
        "    elif column == \"CustomerLastWBBPurchaseDate\":\n",
        "        df[column] = df[column].fillna(4729)\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_processing_train(df):\n",
        "    mapping = {'Multiple Activities':0, 'Other Secondary Activity':1, 'Primary Purchase':2, 'Secondary Purchase':3, 'Transfer Recipient': 4}\n",
        "    df['ActivityType'] = df['ActivityType'].map(mapping)\n",
        "    # Define the mapping dictionary\n",
        "    df['SameState'] = df.apply(lambda row: 1 if pd.notnull(row['CustomerState']) and pd.notnull(row['FacilityState']) and row['CustomerState'].lower() == row['FacilityState'].lower() else 0, axis=1)\n",
        "    df['SameCity'] = df.apply(lambda row: 1 if pd.notnull(row['CustomerCity']) and pd.notnull(row['FacilityCity']) and row['CustomerCity'].lower() == row['FacilityCity'].lower() else 0, axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def feature_processing_test(df):\n",
        "    df['SameState'] = df.apply(lambda row: 1 if pd.notnull(row['CustomerState']) and pd.notnull(row['FacilityState']) and row['CustomerState'].lower() == row['FacilityState'].lower() else 0, axis=1)\n",
        "    df['SameCity'] = df.apply(lambda row: 1 if pd.notnull(row['CustomerCity']) and pd.notnull(row['FacilityCity']) and row['CustomerCity'].lower() == row['FacilityCity'].lower() else 0, axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def getdummy(train_df, test_df, category_variable, suffix='_dummy'):\n",
        "    import pandas as pd\n",
        "    # Convert training data to dummy variables\n",
        "    train_dummy_df = pd.get_dummies(train_df[category_variable]).astype(int).add_suffix(suffix)\n",
        "    # Convert test data to dummy variables\n",
        "    test_dummy_df = pd.get_dummies(test_df[category_variable]).astype(int).add_suffix(suffix)\n",
        "    # Ensure both train and test datasets have the same dummy variable columns\n",
        "    # Add missing dummy variable columns to test data, filled with zeros\n",
        "    missing_cols = set(train_dummy_df.columns) - set(test_dummy_df.columns)\n",
        "    for col in missing_cols:\n",
        "        test_dummy_df[col] = 0\n",
        "    # Reorder test data columns to match train data columns\n",
        "    test_dummy_df = test_dummy_df[train_dummy_df.columns]\n",
        "    # Concatenate dummy variables with original test DataFrame\n",
        "    train_df = pd.concat([train_df, train_dummy_df], axis=1)\n",
        "    # train_df.drop(columns=[category_variable], inplace=True)\n",
        "    test_df = pd.concat([test_df, test_dummy_df], axis=1)\n",
        "    # test_df.drop(columns=[category_variable], inplace=True)\n",
        "\n",
        "    train_df.columns = train_df.columns.astype(str)\n",
        "    test_df.columns = test_df.columns.astype(str)\n",
        "    # if '(UNK)' in train_df.columns:\n",
        "    #     train_df.drop(columns=['(UNK)'], inplace=True)\n",
        "    #     test_df.drop(columns=['(UNK)'], inplace=True)\n",
        "    #     train_dummy_df.drop(columns=['(UNK)'], inplace=True)\n",
        "\n",
        "    return train_df, test_df, train_dummy_df.columns\n",
        "\n",
        "def datedummy(df):\n",
        "    df[\"EventBeginDate_dummy\"] = (df[\"EventBeginDate\"] < 654).astype(int)\n",
        "    df[\"EventEndDate_dummy\"] = (df[\"EventEndDate\"] < 654).astype(int)\n",
        "    df[\"CustomerFirstWBBActionDate_dummy\"] = (df[\"CustomerFirstWBBActionDate\"]< 5023).astype(int)\n",
        "    df[\"CustomerFirstWBBPurchaseDate_dummy\"] = (df[\"CustomerFirstWBBPurchaseDate\"] < 4842).astype(int)\n",
        "    df[\"CustomerLastWBBActionDate_dummy\"] = (df[\"CustomerLastWBBActionDate\"] < 4807).astype(int)\n",
        "    df[\"CustomerLastWBBPurchaseDate_dummy\"] = (df[\"CustomerLastWBBPurchaseDate\"] < 4729).astype(int)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkSWsVSW_DTX",
        "outputId": "e1e01f19-b653-4689-a5a1-17366b5fcae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-c052d4e7d2be>:11: DtypeWarning: Columns (13,14,15,16,17,18,19,20,21,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"DIWBB_Training.csv\")\n"
          ]
        }
      ],
      "source": [
        "# processing for\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "label_encoder = LabelEncoder()\n",
        "from datetime import datetime\n",
        "\n",
        "df = pd.read_csv(\"DIWBB_Training.csv\")\n",
        "df_test = pd.read_csv(\"DIWBB_Test.csv\")\n",
        "submission = pd.read_csv(\"DIWBB_Submission_Template.csv\")\n",
        "\n",
        "#EventRoundName = null -> No activity\n",
        "df = df[~df['EventRoundName'].isnull()]\n",
        "df_test = df_test[~df_test['EventRoundName'].isnull()]\n",
        "\n",
        "#EventRoundName = First Round or First and Second Rounds -> 'Primary Purchase'\n",
        "df_fs = df_test[(df_test['EventRoundName'] == 'First Round') | (df_test['EventRoundName'] == 'First and Second Rounds')]['RecordID']\n",
        "submission.loc[submission['RecordID'].isin(df_fs), 'ActivityType'] = 'Primary Purchase'\n",
        "df = df[~((df['EventRoundName'] == 'First Round') | (df['EventRoundName'] == 'First and Second Rounds'))]\n",
        "df_test = df_test[~((df_test['EventRoundName'] == 'First Round') | (df_test['EventRoundName'] == 'First and Second Rounds'))]\n",
        "# del df_fs\n",
        "\n",
        "#EventRoundName = Regionals and EventSession = All-Session -> 'Primary Purchase'\n",
        "df_ra = df_test[(df_test['EventRoundName'] == 'Regionals') & (df_test['EventSession'] == 'All-Session')]['RecordID']\n",
        "submission.loc[submission['RecordID'].isin(df_ra), 'ActivityType'] = 'Primary Purchase'\n",
        "df = df[~((df['EventRoundName'] == 'Regionals') & (df['EventSession'] == 'All-Session'))]\n",
        "df_test = df_test[~((df_test['EventRoundName'] == 'Regionals') & (df_test['EventSession'] == 'All-Session'))]\n",
        "# del df_ra\n",
        "\n",
        "#ChampionshipYear=2022 and EventRoundName = Regionals\n",
        "df_22r = df_test[(df_test['EventRoundName'] == 'Regionals') & (df_test['ChampionshipYear'] == 2022)]['RecordID']\n",
        "submission.loc[submission['RecordID'].isin(df_22r), 'ActivityType'] = 'Primary Purchase'\n",
        "df = df[~((df['EventRoundName'] == 'Regionals') & (df['ChampionshipYear'] == 2022))]\n",
        "df_test = df_test[~((df_test['EventRoundName'] == 'Regionals') & (df_test['ChampionshipYear'] == 2022))]\n",
        "# del df_22r\n",
        "\n",
        "#ChampionshipYear=2023 and EventRoundName = Regionals and EventBeginDate = EventEndDate and session!= 4\n",
        "df_23r = df_test[(df_test['EventRoundName'] == 'Regionals') & (df_test['ChampionshipYear'] == 2023) & (df_test['EventBeginDate'] == df_test['EventEndDate']) & (df_test['EventSession'] != 'Session 4')]['RecordID']\n",
        "submission.loc[submission['RecordID'].isin(df_23r), 'ActivityType'] = 'Primary Purchase'\n",
        "df = df[~((df['EventRoundName'] == 'Regionals') & (df['ChampionshipYear'] == 2023) & (df['EventBeginDate'] == df['EventEndDate']) & (df['EventSession'] != 'Session 4'))]\n",
        "df_test = df_test[~((df_test['EventRoundName'] == 'Regionals') & (df_test['ChampionshipYear'] == 2023) & (df_test['EventBeginDate'] == df_test['EventEndDate']) & (df_test['EventSession'] != 'Session 4'))]\n",
        "# del df_23r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "U6aLhNzL_DTY",
        "outputId": "74443012-ac29-482f-9479-9327a82eb898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Accuracy: 0.9620689655172414\n",
            "Validation_Accuracy: 0.8264462809917356\n",
            "0:\tlearn: 1.6000401\ttotal: 2.05ms\tremaining: 1.64s\n",
            "100:\tlearn: 1.2280985\ttotal: 2.4s\tremaining: 16.6s\n",
            "200:\tlearn: 1.1433883\ttotal: 32.1s\tremaining: 1m 36s\n",
            "300:\tlearn: 1.1130135\ttotal: 1m 4s\tremaining: 1m 47s\n",
            "400:\tlearn: 1.0975902\ttotal: 1m 19s\tremaining: 1m 19s\n",
            "500:\tlearn: 1.0880552\ttotal: 1m 40s\tremaining: 1m\n",
            "600:\tlearn: 1.0807901\ttotal: 2m 4s\tremaining: 41.2s\n",
            "700:\tlearn: 1.0734523\ttotal: 2m 39s\tremaining: 22.6s\n",
            "799:\tlearn: 1.0652902\ttotal: 4m 8s\tremaining: 0us\n",
            "Train_Accuracy: 0.5635057471264368\n",
            "Validation_Accuracy: 0.5579793340987371\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'numpy.ndarray'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0b3b88834568>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ChampionshipYear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Multiple Activities'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Other Secondary Activity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Primary Purchase'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Secondary Purchase'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Transfer Recipient'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ChampionshipYear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RecordID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-0b3b88834568>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ChampionshipYear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Multiple Activities'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Other Secondary Activity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Primary Purchase'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Secondary Purchase'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'Transfer Recipient'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ChampionshipYear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RecordID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ],
      "source": [
        "#Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "label_encoder = LabelEncoder()\n",
        "from datetime import datetime\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier  # Import CatBoost\n",
        "label_encoder = LabelEncoder()\n",
        "from datetime import datetime\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "df = feature_processing_train(df)\n",
        "df_test = feature_processing_test(df_test)\n",
        "\n",
        "df = dateconvert(df,'CustomerLastWBBPurchaseDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'CustomerLastWBBPurchaseDate','2023-12-31')\n",
        "\n",
        "df = dateconvert(df,'CustomerLastWBBActionDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'CustomerLastWBBActionDate','2023-12-31')\n",
        "\n",
        "df = dateconvert(df,'CustomerFirstWBBActionDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'CustomerFirstWBBActionDate','2023-12-31')\n",
        "\n",
        "df = dateconvert(df,'CustomerFirstWBBPurchaseDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'CustomerFirstWBBPurchaseDate','2023-12-31')\n",
        "\n",
        "df = dateconvert(df,'EventBeginDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'EventBeginDate','2023-12-31')\n",
        "\n",
        "df = dateconvert(df,'EventEndDate','2023-12-31')\n",
        "df_test = dateconvert(df_test,'EventEndDate','2023-12-31')\n",
        "\n",
        "# date_dummy = [\"EventBeginDate_dummy\",\"EventEndDate_dummy\",\"CustomerFirstWBBActionDate_dummy\",\"CustomerFirstWBBPurchaseDate_dummy\",\"CustomerLastWBBActionDate_dummy\",\"CustomerLastWBBPurchaseDate_dummy\"]\n",
        "date_variables = ['EventBeginDate','EventEndDate','CustomerFirstWBBActionDate','CustomerFirstWBBPurchaseDate','CustomerLastWBBActionDate','CustomerLastWBBPurchaseDate']\n",
        "date_variables_year = ['EventBeginDate_year','EventEndDate_year','CustomerFirstWBBActionDate_year','CustomerFirstWBBPurchaseDate_year','CustomerLastWBBActionDate_year','CustomerLastWBBPurchaseDate_year']\n",
        "date_variables_month = ['EventBeginDate_month','EventEndDate_month','CustomerFirstWBBActionDate_month','CustomerFirstWBBPurchaseDate_month','CustomerLastWBBActionDate_month','CustomerLastWBBPurchaseDate_month']\n",
        "date_variables_weekday = ['EventBeginDate_weekday','EventEndDate_weekday','CustomerFirstWBBActionDate_weekday','CustomerFirstWBBPurchaseDate_weekday','CustomerLastWBBActionDate_weekday','CustomerLastWBBPurchaseDate_weekday']\n",
        "\n",
        "dummy_date_variables_year = []\n",
        "for i in range(len(date_variables_year)):\n",
        "    df, df_test, dummy = getdummy(df, df_test, date_variables_year[i], suffix=f'_{date_variables_year[i]}')\n",
        "    dummy_date_variables_year = dummy_date_variables_year + list(dummy)\n",
        "\n",
        "dummy_date_variables_month = []\n",
        "for i in range(len(date_variables_month)):\n",
        "    df, df_test, dummy = getdummy(df, df_test, date_variables_month[i], suffix=f'_{date_variables_month[i]}')\n",
        "    dummy_date_variables_month = dummy_date_variables_month + list(dummy)\n",
        "\n",
        "dummy_date_variables_weekday = []\n",
        "for i in range(len(date_variables_weekday)):\n",
        "    df, df_test, dummy = getdummy(df, df_test, date_variables_weekday[i], suffix=f'_{date_variables_weekday[i]}')\n",
        "    dummy_date_variables_weekday = dummy_date_variables_weekday + list(dummy)\n",
        "\n",
        "df, df_test, dummy_EventRoundName = getdummy(df, df_test, \"EventRoundName\", suffix='_EventRoundName')\n",
        "df, df_test, dummy_EventSession = getdummy(df, df_test, \"EventSession\", suffix='_EventSession')\n",
        "df, df_test, dummy_FacilityDescription = getdummy(df, df_test, \"FacilityDescription\", suffix='_FacilityDescription')\n",
        "df, df_test, dummy_CustomerState = getdummy(df, df_test, \"CustomerState\", suffix='_CustomerState')\n",
        "df, df_test, dummy_FacilityState = getdummy(df, df_test, \"FacilityState\", suffix='_FacilityState')\n",
        "df, df_test, dummy_HasCustomerClickedOrOpenedEmailsSixMonthsPrior = getdummy(df, df_test, \"HasCustomerClickedOrOpenedEmailsSixMonthsPrior\", suffix='_HasCustomerClickedOrOpenedEmailsSixMonthsPrior')\n",
        "df, df_test, dummy_HostingInstitution = getdummy(df, df_test, \"HostingInstitution\", suffix='_HostingInstitution')\n",
        "df, df_test, dummy_IsCustomerInNCAAMembership = getdummy(df, df_test, 'IsCustomerInNCAAMembership', suffix='_IsCustomerInNCAAMembership')\n",
        "df, df_test, dummy_FacilityName = getdummy(df, df_test, 'FacilityName', suffix='_FacilityName')\n",
        "df, df_test, dummy_IsEventFinalSite = getdummy(df, df_test, 'IsEventFinalSite', suffix='_IsEventFinalSite')\n",
        "# df, df_test, dummy_FacilityCity = getdummy(df, df_test, 'FacilityCity', suffix='_FacilityCity')\n",
        "# df, df_test, dummy_FacilityZipCode = getdummy(df, df_test, 'FacilityZipCode', suffix='_FacilityZipCode')\n",
        "\n",
        "\n",
        "# date_dummy +\n",
        "features = date_variables + dummy_date_variables_year + dummy_date_variables_month + dummy_date_variables_weekday + \\\n",
        "     list(dummy_FacilityState) + list(dummy_CustomerState) + list(dummy_FacilityDescription) + \\\n",
        "     list(dummy_EventSession) + list(dummy_EventRoundName) + \\\n",
        "    list(dummy_HostingInstitution) + list(dummy_HasCustomerClickedOrOpenedEmailsSixMonthsPrior) + \\\n",
        "    list(dummy_IsCustomerInNCAAMembership) + list(dummy_IsEventFinalSite) + \\\n",
        "    list(dummy_FacilityName) + \\\n",
        "    ['SameState', 'SameCity']\n",
        "\n",
        "y = df['ActivityType']\n",
        "num_classes = len(df['ActivityType'].unique())\n",
        "X_2022 = df[df['ChampionshipYear'] == 2022][features]\n",
        "X_2023 = df[df['ChampionshipYear'] == 2023][features]\n",
        "y_2022 = df[df['ChampionshipYear'] == 2022]['ActivityType']\n",
        "y_2023 = df[df['ChampionshipYear'] == 2023]['ActivityType']\n",
        "\n",
        "Xys = [[X_2022,y_2022],[X_2023,y_2023]]\n",
        "acc = []\n",
        "#['Multiple Activities' 'No Activity' 'Other Secondary Activity','Primary Purchase' 'Secondary Purchase' 'Transfer Recipient']\n",
        "\n",
        "results = pd.DataFrame(columns=['RecordID', 'Result'])\n",
        "\n",
        "for index, Xy in enumerate(Xys):\n",
        "\n",
        "# Split data into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(Xy[0], Xy[1], test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "    if index == 0:\n",
        "        model = xgb.XGBClassifier(objective='multi:softmax',\n",
        "                                  num_class=num_classes,\n",
        "                                  reg_alpha=0,  # Adjust this value for L1 regularization\n",
        "                                  reg_lambda=0,  # Adjust this value for L2 regularization\n",
        "                                  gamma=0,  # Adjust this value for complexity control\n",
        "                                  max_depth=50,  # Adjust this value for tree depth regularization\n",
        "                                  min_child_weight=1)  # Adjust this value for regularization\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    elif index == 1:\n",
        "        # Use CatBoost model\n",
        "        model = CatBoostClassifier(loss_function='MultiClass',\n",
        "                                   n_estimators=800,\n",
        "                                   depth=16,\n",
        "                                   learning_rate=0.01,\n",
        "                                   verbose=100)  # Adjust hyperparameters as needed\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_train_predict = model.predict(X_train)\n",
        "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
        "    print(\"Train_Accuracy:\", accuracy_train)\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_val)\n",
        "    # Evaluate model\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    print(\"Validation_Accuracy:\", accuracy)\n",
        "    acc.append(accuracy)\n",
        "\n",
        "    y_test = model.predict(df_test[df_test['ChampionshipYear'] == index+2022][features])\n",
        "    mapping = {0:'Multiple Activities', 1:'Other Secondary Activity', 2:'Primary Purchase', 3:'Secondary Purchase', 4:'Transfer Recipient'}\n",
        "    y_test = np.array([mapping[val] for val in y_test])\n",
        "\n",
        "    id_df = df_test[df_test['ChampionshipYear'] == index+2022]['RecordID']\n",
        "    id_df.reset_index(drop=True, inplace=True)\n",
        "    result_df = pd.DataFrame(y_test, columns=['Result'])\n",
        "    result_df.reset_index(drop=True, inplace=True)\n",
        "    result = pd.concat([id_df, result_df],axis=1)\n",
        "    results = pd.concat([results,result],axis=0)\n",
        "\n",
        "submission = pd.merge(submission, results, how='left', on='RecordID')\n",
        "submission.loc[~submission['Result'].isna(),'ActivityType'] = submission.loc[~submission['Result'].isna(),'Result']\n",
        "submission.drop(columns=['Result'], inplace=True)\n",
        "current_time = datetime.now()\n",
        "formatted_date = current_time.strftime(\"%Y%m%d\")\n",
        "formatted_time = current_time.strftime(\"%H%M%S\")\n",
        "submission.to_csv(f\"submission_LastDance_{formatted_date}_{formatted_time}_{acc[0]:.4f}_{acc[1]:.4f}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier  # Import CatBoost\n",
        "label_encoder = LabelEncoder()\n",
        "from datetime import datetime\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Assume feature_processing_train, feature_processing_test, dateconvert, getdummy functions are defined above\n",
        "\n",
        "# Feature processing and dummy variable creation assumed to be defined above\n",
        "\n",
        "# Define features and labels\n",
        "# date_dummy +\n",
        "features = date_variables + dummy_date_variables_year + dummy_date_variables_month + dummy_date_variables_weekday + \\\n",
        "     list(dummy_FacilityState) + list(dummy_CustomerState) + list(dummy_FacilityDescription) + \\\n",
        "     list(dummy_EventSession) + list(dummy_EventRoundName) + \\\n",
        "    list(dummy_HostingInstitution) + list(dummy_HasCustomerClickedOrOpenedEmailsSixMonthsPrior) + \\\n",
        "    list(dummy_IsCustomerInNCAAMembership) + list(dummy_IsEventFinalSite) + \\\n",
        "    list(dummy_FacilityName) + \\\n",
        "    ['SameState', 'SameCity']\n",
        "\n",
        "y = df['ActivityType']\n",
        "num_classes = len(df['ActivityType'].unique())\n",
        "X_2022 = df[df['ChampionshipYear'] == 2022][features]\n",
        "X_2023 = df[df['ChampionshipYear'] == 2023][features]\n",
        "y_2022 = df[df['ChampionshipYear'] == 2022]['ActivityType']\n",
        "y_2023 = df[df['ChampionshipYear'] == 2023]['ActivityType']\n",
        "\n",
        "Xys = [[X_2022, y_2022], [X_2023, y_2023]]\n",
        "acc = []\n",
        "\n",
        "results = pd.DataFrame(columns=['RecordID', 'Result'])\n",
        "\n",
        "for index, Xy in enumerate(Xys):\n",
        "    # Split data into train and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(Xy[0], Xy[1], test_size=0.2, random_state=42)\n",
        "\n",
        "    if index == 0:\n",
        "        model = xgb.XGBClassifier(objective='multi:softmax',\n",
        "                                  num_class=num_classes,\n",
        "                                  reg_alpha=0,  # Adjust this value for L1 regularization\n",
        "                                  reg_lambda=0,  # Adjust this value for L2 regularization\n",
        "                                  gamma=0,  # Adjust this value for complexity control\n",
        "                                  max_depth=50,  # Adjust this value for tree depth regularization\n",
        "                                  min_child_weight=1)  # Adjust this value for regularization\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    elif index == 1:\n",
        "        # Use CatBoost model\n",
        "        model = CatBoostClassifier(loss_function='MultiClass',\n",
        "                                   n_estimators=1500,\n",
        "                                   depth=10,\n",
        "                                   learning_rate=0.1,\n",
        "                                   verbose=100)  # Adjust hyperparameters as needed\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_predict = model.predict(X_train)\n",
        "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
        "    print(\"Train_Accuracy:\", accuracy_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_val)\n",
        "    # Evaluate model\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    print(\"Validation_Accuracy:\", accuracy)\n",
        "    acc.append(accuracy)\n",
        "\n",
        "    # Test set predictions and results compilation assumed to be defined here\n",
        "\n",
        "submission = pd.merge(submission, results, how='left', on='RecordID')\n",
        "submission.loc[~submission['Result'].isna(), 'ActivityType'] = submission.loc[~submission['Result'].isna(), 'Result']\n",
        "submission.drop(columns=['Result'], inplace=True)\n",
        "current_time = datetime.now()\n",
        "formatted_date = current_time.strftime(\"%Y%m%d\")\n",
        "formatted_time = current_time.strftime(\"%H%M%S\")\n",
        "submission.to_csv(f\"submission_LastDance_{formatted_date}_{formatted_time}_{acc[0]:.4f}_{acc[1]:.4f}.csv\", index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bHONjaYxHZv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIDOXb3M_DTZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_prob = model.predict_proba(X_val)\n",
        "\n",
        "# Compute AUC for each class\n",
        "auc_scores = []\n",
        "for i in range(num_classes):\n",
        "    auc_score = roc_auc_score((y_val == i).astype(int), y_prob[:, i])\n",
        "    auc_scores.append(auc_score)\n",
        "    print(f\"AUC for class {i}: {auc_score}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(num_classes):\n",
        "    fpr, tpr, _ = roc_curve((y_val == i).astype(int), y_prob[:, i])\n",
        "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc_scores[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2CJ-Ktx_DTZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get feature importances\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Get feature names\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Sort feature importances in descending order\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "\n",
        "\n",
        "# Rearrange feature names based on importance rank\n",
        "sorted_feature_names = [feature_names[i] for i in indices]\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(X_train.shape[1]), sorted_feature_names, rotation=90)\n",
        "plt.xlim([-1, X_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(sorted_feature_names)):\n",
        "    print(sorted_feature_names[i])\n",
        "    print(importances[indices][i])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}